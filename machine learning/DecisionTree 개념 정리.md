# :mag: Index

- [의사결정나무(Decision Tree)는 뭘까?](#:radio_button:-What-is-Decision-Tree)
- [의사결정 나무의 철학: Information Gain](#information-gain)
- ㅇ
- ㅇ
- ㅇ

---

### :radio_button: What is Decision Tree

의사결정나무란 데이터 사이 존재하는 __패턴__을 찾아 이 규칙들의 __조합__으로 예측 모델을 만드는데 쓰이는 알고리즘으로 기계학습의 기초가 되는 알고리즘 중 하나이다.



그림으로 그렸을때 트리의 형태를 이루기 때문에 '나무' 라는 말이 붙었는데 이는 추후 여러 의사결정나무를 앙상블 기법을 통해 활용한 __Random Forest__ 알고리즘에도 영향을 주었다.



의사결정나무는 설명변수를 __\*하나씩만\*__ 활용하여 가지뻗기를 진행하는데 이는 우리가 어릴적 한번씩 해봤던 '스무고개' 놀이를 통해 이해할 수 있다. 

> 의사결정나무에 대한 설명을 보면 `설명변수`라는 용어가 쓰이는데 `입력특성`,`독립변수` 정도로 이해하면 된다.

![스무고개 그림](https://t1.daumcdn.net/thumb/R720x0/?fname=http://t1.daumcdn.net/brunch/service/user/1oU7/image/OG5rMwYpRcG4gRPFv8qgLslNLTQ.png)

[이미지 출처](https://www.google.com/url?sa=i&url=https%3A%2F%2Fbrunch.co.kr%2F%40kakao-it%2F157&psig=AOvVaw1D35xHZ-Geohyk-iCIprD-&ust=1601041536507000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCIDxttT2gewCFQAAAAAdAAAAABAX)



다음과 같은 스무고개 놀이를 했을 때 __`다리`__ ,__`고양이와 크기가 비슷`__ , __`바다에 사는`__ 은 모두 위에서 언급한 설명변수에 해당한다. 데이터에 대한 패턴을 찾아 트리 구조로 규칙을 조합해놓은 모양이다. 한번에 설명변수 하나씩만을 이용해 가지를 뻗게되어 __terminal node__ , __leaf node__ 라고 부르는 트리의 최하위 항목들을 살펴보면 초기 데이터의 상호 베타적인 집합으로 분류되어 있는것을 확인할 수 있다.



의사결정나무는 이런 모양으로 규칙을 조합하여 데이터에 대한 예측 모델을 이룬다. 이는 `분류(Classification)` 문제와 `회귀(Regression)` 문제 모두 적용가능한데 , 분류 문제의 경우 해당 데이터가 최종적으로 속한 최하위 그룹의 최빈값을 예측값으로 활용하고 회귀 문제의 경우 그 그룹내 데이터의 평균값을 예측값으로 활용한다.즉, N개의 최하위 노드를 갖는 의사결정나무로부터 얻을 수 있는 예측값의 종류는 `분류|회귀 문제와 상관없이 동일하게 최대 N개이다.`

---

### :radio_button: Information Gain







 



### :arrow_right:항목





### :arrow_right:항목





### :arrow_right:항목





### :arrow_right:항목





### :arrow_right:항목





### :arrow_right:항목





### :arrow_right:항목





### :arrow_right:항목





### :arrow_right:항목





### :arrow_right:항목





### :arrow_right:항목





### :arrow_right:항목





### :arrow_right:항목





### :arrow_right:항목
