# Course Study from [CSC321](https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/) 



### [2021.01.09]

__`Topic`__ : **Neural Network quick review to Gradient vanishing & exploding problem** 

__`Notes`__ : 

- [https://drive.google.com/file/d/15_-n3O7gaMyRTqq5-WC9hfms1Xtea2Jp/view?usp=sharing](https://drive.google.com/file/d/15_-n3O7gaMyRTqq5-WC9hfms1Xtea2Jp/view?usp=sharing) 

__`Links`__ :

- [https://wikidocs.net/61375](https://wikidocs.net/61375) 
- [https://m.blog.naver.com/PostView.nhn?blogId=pshkhh&logNo=221203426679&proxyReferer=https:%2F%2Fwww.google.com%2Fhttps://brunch.co.kr/@chris-song/39](https://m.blog.naver.com/PostView.nhn?blogId=pshkhh&logNo=221203426679&proxyReferer=https:%2F%2Fwww.google.com%2Fhttps://brunch.co.kr/@chris-song/39) 
- [https://t-lab.tistory.com/14](https://t-lab.tistory.com/14) 
- [https://aikorea.org/blog/rnn-tutorial-3/](https://aikorea.org/blog/rnn-tutorial-3/) 
- [https://velog.io/@dscwinterstudy/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D2-5%EC%9E%A5-gnk6bhirc3](https://velog.io/@dscwinterstudy/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D2-5%EC%9E%A5-gnk6bhirc3) 
- [https://m.blog.naver.com/worb1605/221187949828](https://m.blog.naver.com/worb1605/221187949828) 
- [https://ganghee-lee.tistory.com/30](https://ganghee-lee.tistory.com/30) 
- [https://heehehe-ds.tistory.com/entry/Deep-Learning-%EC%86%90%EC%8B%A4%ED%95%A8%EC%88%98loss-function-%EC%98%B5%ED%8B%B0%EB%A7%88%EC%9D%B4%EC%A0%80optimizer](https://heehehe-ds.tistory.com/entry/Deep-Learning-%EC%86%90%EC%8B%A4%ED%95%A8%EC%88%98loss-function-%EC%98%B5%ED%8B%B0%EB%A7%88%EC%9D%B4%EC%A0%80optimizer) 
- [https://ydseo.tistory.com/41](https://ydseo.tistory.com/41) 
- [https://cs224d.stanford.edu/notebooks/vanishing_grad_example.html](https://cs224d.stanford.edu/notebooks/vanishing_grad_example.html) 
- [https://simonjisu.github.io/numpyseries/2018/03/14/rnnlstm2.html](https://simonjisu.github.io/numpyseries/2018/03/14/rnnlstm2.html) 
- [https://mmuratarat.github.io/2019-02-07/bptt-of-rnn](https://mmuratarat.github.io/2019-02-07/bptt-of-rnn) 
- [https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/](https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/) 

__`Next`__ : 2021.01.16 9:30 PM KST

- [http://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/](http://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/readings/L15 Exploding and Vanishing Gradients.pdf)
- __Lecture 5: Multilayer Perceptrons (박희원) , Lecture 6: Backpropagation (이동재)__ 

---



### [2021.01.16]

__`Topic`__  : __Lecture 5: Multilayer Perceptrons (박희원) , Lecture 6: Backpropagation (이동재)__ 

__`Notes`__  : 

- [https://drive.google.com/file/d/1p446nFckVgzjhYFzZ7EABXLRX9Mq3QLN/view?usp=sharing](https://drive.google.com/file/d/1p446nFckVgzjhYFzZ7EABXLRX9Mq3QLN/view?usp=sharing) (희원)
- [https://drive.google.com/file/d/1BydNGPxWEwRxiJobvu5dPq88xhRO2ypU/view?usp=sharing](https://drive.google.com/file/d/1BydNGPxWEwRxiJobvu5dPq88xhRO2ypU/view?usp=sharing) (동재)

__`Links`__ : 

>  Multilayer Perceptrons 

- [http://hleecaster.com/ml-perceptron-concept/](http://hleecaster.com/ml-perceptron-concept/) 
- [http://blog.naver.com/PostView.nhn?blogId=apr407&logNo=221238611771&parentCategoryNo=&categoryNo=55&viewDate=&isShowPopularPosts=true&from=search](http://blog.naver.com/PostView.nhn?blogId=apr407&logNo=221238611771&parentCategoryNo=&categoryNo=55&viewDate=&isShowPopularPosts=true&from=search) 
- [https://untitledtblog.tistory.com/27](https://untitledtblog.tistory.com/27) 
- [https://choosunsick.github.io/post/neural_network_intro/](https://choosunsick.github.io/post/neural_network_intro/) 
- [http://www.datamarket.kr/xe/board_LCmL04/26245](http://www.datamarket.kr/xe/board_LCmL04/26245) 

> Backpropagation

- [https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/readings/L06%20Backpropagation.pdf](https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/readings/L06%20Backpropagation.pdf) 
- [https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/slides/lec8a.pdf](https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/slides/lec8a.pdf) 
- [https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/slides/lec8b.pdf](https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/slides/lec8b.pdf) 

__`Next`__ : 2021.01.23 9:00 PM KST

- [http://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/](https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/) 
- __Lecture 7: Optimization (이찬주)__ 

---



### [2021.01.23]

__`Topic`__ : __Lecture 7: Optimization 1st part (이찬주)__ 

__`Notes`__ :

- [https://drive.google.com/file/d/1gq4tCKfcwQ_QYRO8XYhdR3Y3UTfJQXNd/view?usp=sharing](https://drive.google.com/file/d/1gq4tCKfcwQ_QYRO8XYhdR3Y3UTfJQXNd/view?usp=sharing) 

__`Links`__ : 

- [https://hyunw.kim/blog/2017/11/01/Optimization.html](https://hyunw.kim/blog/2017/11/01/Optimization.html) 
- [Gradient Descent Optimization Algorithms 정리](http://shuuki4.github.io/deep%20learning/2016/05/20/Gradient-Descent-Algorithm-Overview.html) , (shuuki4.github.io)

__`Next`__ : 2021.01.30 9:00 PM KST 

- [http://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/](https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/) 
- __Lecture 7: Optimization (from Momentum 민채정)__ 

---



### [2021.01.30]

__`Topic`__  **:** **Lecture 7: Optimization (2nd , 민채정)**

__`Notes`__ : 업로드 예정

__`Links`__ : 

- [Derivative of Logistic Regression](https://medium.com/analytics-vidhya/derivative-of-log-loss-function-for-logistic-regression-9b832f025c2d)
- [what is convex function?](https://ratsgo.github.io/convex%20optimization/2017/12/26/convexfunction/)
- [cost-function](https://www.kdnuggets.com/2020/05/5-concepts-gradient-descent-cost-function.html)
- [https://www.slideshare.net/hyeseunglee6/ch6-75888743?from_action=save](https://www.slideshare.net/hyeseunglee6/ch6-75888743?from_action=save) 
- [https://sacko.tistory.com/42https://twinw.tistory.com/247](https://sacko.tistory.com/42https://twinw.tistory.com/247) 

__`Next`__ : 2021.02.06 9:00 PM KST

- [http://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/](https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/) 
- __Lecture 9: Generalization 1st part ( ~weight decay , 이동재)__ 
- 순서 고정 : `이동재` - `박희원` - `이찬주` - `민채정`

---



### [2021.02.06]

__`Topic`__  **:** **Lecture 9: Generalization (이동재)**

__`Notes`__ : 

- [https://drive.google.com/file/d/1X-KzORli9CRrPun3qsMfREAr08cbLCWv/view?usp=sharing](https://drive.google.com/file/d/1X-KzORli9CRrPun3qsMfREAr08cbLCWv/view?usp=sharing) 

__`Links`__ : 

- [https://blog.naver.com/mykepzzang/220837959160](https://blog.naver.com/mykepzzang/220837959160) (베이즈 에러 도출 과정 확률과 표준편차 참고자료)
- [https://warm-uk.tistory.com/44](https://warm-uk.tistory.com/44) (BottleNeck 층을 활용한 Inception)
- [https://munjeongkang.github.io/ANN2/](https://munjeongkang.github.io/ANN2/) (model capacity)
- [https://light-tree.tistory.com/216](https://light-tree.tistory.com/216) (Weight decay , L1&L2 regularizer)
- [https://hyeonnii.tistory.com/353](https://hyeonnii.tistory.com/353) (Bayes Error)

__`Next`__ : 2021.02.20 9:00 PM KST

- [http://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/](https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/) 
- __Lecture 11: Convolutional Networks (박희원)__ 

---



### [2021.02.20]

__`Topic`__ : __Lecture 11: Convolutional Networks (박희원)__ 

__`Notes`__ : 

- [https://drive.google.com/file/d/1F8j0ubTHnhKQ0nA8Qf7bysDkuaFlfmZ4/view?usp=sharing](https://drive.google.com/file/d/1F8j0ubTHnhKQ0nA8Qf7bysDkuaFlfmZ4/view?usp=sharing) 

__`Links`__ : 

- [https://untitledtblog.tistory.com/150](https://untitledtblog.tistory.com/150) 
- [https://underflow101.tistory.com/44](https://underflow101.tistory.com/44) 
- [https://underflow101.tistory.com/25](https://underflow101.tistory.com/25) 
- [https://excelsior-cjh.tistory.com/180](https://excelsior-cjh.tistory.com/180) 
- [https://dsbook.tistory.com/59](https://dsbook.tistory.com/59) 
- [https://nittaku.tistory.com/264](https://nittaku.tistory.com/264) 

__`Next`__ : 2021.02.27 9:00 PM KST

- [http://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/](https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/) 
- **Lecture 12: Image Classification (이찬주)** 

```
1.두 데이터 셋 간단 소개 (MNIST , Caltech101)
2.Image NET 대회 간단 소개
3.Conv net 사이즈 구하는 방법 (표기 방법)
4.LeNET , AlexNET , GoogleNET , (LeNET , AlexNET 은 너무 깊게할 필요 없고 GoogleNET은 fully convolutional 이라는 의미가 뭔지)
```

---



### [2021.02.27]

__`Topic`__ : __Lecture 12: Image Classification (이찬주) , CNN misc part (이동재)__ 

__`Notes`__ : 

- [https://drive.google.com/file/d/1GYaiD1fUVTdfW4P82oZz8oK5EJTm8xgX/view?usp=sharing](https://drive.google.com/file/d/1GYaiD1fUVTdfW4P82oZz8oK5EJTm8xgX/view?usp=sharing) (이찬주)
- [https://drive.google.com/file/d/1npGyII1IWSrQQN_LGjtjK7RtgibJFvX-/view?usp=sharing](https://drive.google.com/file/d/1npGyII1IWSrQQN_LGjtjK7RtgibJFvX-/view?usp=sharing) (이동재)

__`Links`__ : 

- [https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/slides/lec12.pdf](https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/slides/lec12.pdf) (Lecture 12 slide) 
- [https://yjjo.tistory.com/8](https://yjjo.tistory.com/8) (start of CNN , concept of receptive field , how to calculate Conv. net size) 
- [https://bskyvision.com/421](https://bskyvision.com/421) (all about AlexNet : info-share , ReLU , local response normalization) 
- [https://bskyvision.com/422](https://bskyvision.com/422) (what is top-5 , top-1 error ?)

__`Next`__ : 2021.03.06 9:00 PM KST

- [https://m.blog.naver.com/laonple/220710707354](https://m.blog.naver.com/laonple/220710707354) (라온피플) 
- **Special Lecture : Inception , VGG Net , Res Net (이동재 , 민채정)** 

> __Google Net (이동재)__ 
>
> - 1X1 Convolution
> - Inception module (different kernel size , naive & advanced)
> - global average pooling
> - auxilary classifier

> __VGG Net , Res Net (민채정)__ 
>
> - important features of vgg net ( diff between 16 & 19 ?)
> - concept of skip connection from Res Net 
> - R-CNN , Fast R-CNN , Faster R-CNN 은 이번 파트 X

***



### [2021.03.06]

__`Topic`__ : __Lecture 12.3: GooLeNet (이동재)__ 

__`Notes`__ : 

- [https://drive.google.com/file/d/1_PMmX5JODykn1q1667IbfDbSi5moxNY-/view?usp=sharing](https://drive.google.com/file/d/1_PMmX5JODykn1q1667IbfDbSi5moxNY-/view?usp=sharing) (이동재)

__`Links`__ : 

- [https://blog.naver.com/laonple/220686328027](https://blog.naver.com/laonple/220686328027) (GooLeNet Lecture Note 1~5) 
- [https://bskyvision.com/539](https://bskyvision.com/539) (Inception V1 soft review) 
- [https://89douner.tistory.com/62](https://89douner.tistory.com/62) (concatenation in Inception module) 
- [https://jetsonaicar.tistory.com/16](https://jetsonaicar.tistory.com/16) (Global Average Pooling , explained)
- [https://lv99.tistory.com/21](https://lv99.tistory.com/21) (1X1 Conv. layer , explained)

__`Next`__ : 2021.03.13 9:00 PM KST

- **Special Lecture : VGG Net , Res Net (민채정)** 

- [https://blog.naver.com/laonple/220738560542](https://blog.naver.com/laonple/220738560542) (VGG Net [1] ~ VGG Net [2])
- [https://blog.naver.com/laonple/220761052425](https://blog.naver.com/laonple/220761052425) (Res Net [1] ~ Res Net [3])

> __Will Cover__ 
>
> _VGG Net_ : using only 3X3 kernel ? (what is factorizing colvolution filter ?)
>
> _VGG Net_ : how to deal with gradient vanish/exploding problem (pre-trained kernel initializing)
>
> _VGG Net_ : technique on how-to train/test dataset (scale jittering) <- 어려운 개념이니 간단하게만
>
> _Rest Net_ : what is residual learning? ( Shortcut-connection? Identity mapping?)
>
> _Rest Net_ : what features resnet team took from VGG? (common vs. diff)
>
> _Rest Net_ : BottleNeck Layer (only for models with layers>50)
>
> _Rest Net_ : other experiment with CIFAR dataset (going for 1000 layers)

​	

***



### [2021.03.13]

__`Topic`__ : __Lecture 12.4: VGG , ResNet (민채정,이동재)__ 

__`Notes`__ : 

- [https://drive.google.com/file/d/1HMu1LWBzk_FtQoB9m-0ti03_dMNYo3YG/view?usp=sharing](https://drive.google.com/file/d/1HMu1LWBzk_FtQoB9m-0ti03_dMNYo3YG/view?usp=sharing) 

__`Links`__ : 

- [https://blog.naver.com/laonple/220710707354](https://blog.naver.com/laonple/220710707354) (VGG : Conv. Factorizing) 
- [https://brunch.co.kr/@kmbmjn95/37](https://brunch.co.kr/@kmbmjn95/37) (ResNet : how 'residual' idea came up) 
- [https://www.stand-firm-peter.me/2020/09/26/resnet/](https://www.stand-firm-peter.me/2020/09/26/resnet/) (ResNet : 최강 자료1. 모든 설명 다 있음) 
- [https://www.stand-firm-peter.me/2020/09/30/resnet_2/](https://www.stand-firm-peter.me/2020/09/30/resnet_2/) (ResNet : 최강 자료2. 모든 설명 다 있음)
- [https://ratsgo.github.io/deep%20learning/2017/10/09/CNNs/](https://ratsgo.github.io/deep%20learning/2017/10/09/CNNs/) (ResNet : DenseNet 언급)

__`Next`__ : 2021.03.20 9:00 PM KST

- **Object Detection : R-CNN , SPPNET (Hayden)** 

- [https://blog.naver.com/laonple/220731472214](https://blog.naver.com/laonple/220731472214) (GooLeNet [6])

> __Will Cover__ 
>
> - Object Classification VS. Object Detection ?
>   - Bounding Box , mAP , IOU
> - What is R-CNN ? 
>   - SIFT , HOG
>   - Selective search
> - How Berkeley team applied R-CNN ?
>   - PASCAL VOL
>   - fine-tuning
> - Limits of R-CNN & How SPPNet came up
>   - dealing with fixed input size
>   - how many crops/warps

- 순서 변경 : `이동재` -  `민채정` - `박희원` - `이찬주` - `김진원`

---

​	

### [2021.03.20]

__`Topic`__ : __Lecture 13: Object Detection, R-CNN & SPPNET (Hayden)__ 

__`Notes`__ : 

- [https://drive.google.com/file/d/1CymQUZRUMwj4uCGWzFqZj48_HEP8scNo/view?usp=sharing](https://drive.google.com/file/d/1CymQUZRUMwj4uCGWzFqZj48_HEP8scNo/view?usp=sharing) 

__`Links`__ : 

- [https://woosikyang.github.io/fast-rcnn.html](https://woosikyang.github.io/fast-rcnn.html) 
- [https://nuggy875.tistory.com/21](https://nuggy875.tistory.com/21) 
- [https://ganghee-lee.tistory.com/35](https://ganghee-lee.tistory.com/35) 
- [https://blog.naver.com/PostView.nhn?blogId=isu112600&logNo=221583808984](https://blog.naver.com/PostView.nhn?blogId=isu112600&logNo=221583808984) 
- [https://woosikyang.github.io/fast-rcnn.html](https://woosikyang.github.io/fast-rcnn.html) 

__`Next`__ : 2021.03.27 9:00 PM KST

- __Object Detection : R-CNN & SPPNET details (Chanju, James)__ 
- [https://blog.naver.com/laonple/220731472214](https://blog.naver.com/laonple/220731472214) ( (GooLeNet [6])

> __Will Cover__ 
>
> - R-CNN : Background
>   - Computer Vision , selective search , SIFT , HOG , DPM
> - R-CNN : Architecture
>   - 3-modules
> - R-CNN : How to test ? (detect , forward)
>   - NMS
> - R-CNN : How to evaluate?
>   - mAP , different metrics
> - R-CNN : How to train?
>   - different IOU threshold
>   - Bbox regressor understanding
> - R-CNN : Limits

---

​	

### [2021.03.27]

__`Topic`__ : __Lecture 13.2: Object Detection : R-CNN & SPPNET details (Chanju, James)__ 

__`Notes`__ : 

- [https://drive.google.com/file/d/12qj8R53HCYFz8ZcKlukv1pKEM-rM5_4e/view?usp=sharing](https://drive.google.com/file/d/12qj8R53HCYFz8ZcKlukv1pKEM-rM5_4e/view?usp=sharing) [James]

__`Links`__ : 

- [https://arxiv.org/pdf/1311.2524.pdf](https://arxiv.org/pdf/1311.2524.pdf) (original r-cnn thesis)
- [https://wiserloner.tistory.com/1174](https://wiserloner.tistory.com/1174) (r-cnn background, selective search details)
- [https://lilianweng.github.io/lil-log/2017/12/31/object-recognition-for-dummies-part-3.html#model-workflow](https://lilianweng.github.io/lil-log/2017/12/31/object-recognition-for-dummies-part-3.html#model-workflow) (hard negative mining)
- [https://nuggy875.tistory.com/21](https://nuggy875.tistory.com/21) (how to train each modules)
- [https://dyndy.tistory.com/275](https://dyndy.tistory.com/275) (NMS)
- [https://pacientes.github.io/posts/2021/02/ml_ap_map/](https://pacientes.github.io/posts/2021/02/ml_ap_map/) (Confidence score)
- [http://blog.naver.com/PostView.nhn?blogId=sogangori&logNo=221224276320](http://blog.naver.com/PostView.nhn?blogId=sogangori&logNo=221224276320) mAP
- [https://eehoeskrap.tistory.com/183](https://eehoeskrap.tistory.com/183) (end-to-end)

__`Next`__ : 2021.04.03 9:00 PM KST

- __Object Detection : SPPNET , Fast-RCNN details (Chanju, James)__ 
- [https://blog.naver.com/laonple/220731472214](https://blog.naver.com/laonple/220731472214) ( GooLeNet [6])
- [https://blog.naver.com/laonple/220776743537](https://blog.naver.com/laonple/220776743537) ( ResNet [4])

> __Will Cover__ 
>
> - SPP Net : 
>   - What's improved from R-CNN ? (idea, keywords)
>   - SPP Net flow (rough) (compared with R-CNN)
>   - SPP layer details (bin, BoW, how to calculate output)
>   - Practical training (Single-size, Multi-size training)
>   - Performance in fields (Classification, Detection)
>   - SPP Net Limits
> - Fast R-CNN : 
>   - what's improved from SPP Net ? (idea, keywords)
>   - Fast R-CNN flow (rough) (compared with SPP Net)
>   - training Fast R-CNN (multi-task loss function, Hierarchical Sampling)
>   -  test methods (truncated SVD)
>   - Fast R-CNN Limits

_Future models of object detection :_ `SPPNet` , `Fast R-CNN` , `Faster R-CNN` , `YOLO v1` 

---

​	

### [2021.04.03]

__`Topic`__ : __Lecture 13.3: Object Detection : SPPNET details, Fast R-CNN basic (Chanju, James)__ 

__`Notes`__ : 

- [https://drive.google.com/file/d/1IQHx6BPhMwCURbBuw6QBcBeLk8YSUnZg/view?usp=sharing](https://drive.google.com/file/d/1IQHx6BPhMwCURbBuw6QBcBeLk8YSUnZg/view?usp=sharing) [Chanju]
- [https://drive.google.com/file/d/1bQAmtjUexd1lbpZgRB_sKC8VOwPMs064/view?usp=sharing](https://drive.google.com/file/d/1bQAmtjUexd1lbpZgRB_sKC8VOwPMs064/view?usp=sharing) [James]

__`Links`__ : 

> SPP Net

- [https://arxiv.org/pdf/1406.4729.pdf](https://arxiv.org/pdf/1406.4729.pdf) (original spp net thesis)
- [https://driip.me/5743aed5-c630-4900-b367-9987a088661a](https://driip.me/5743aed5-c630-4900-b367-9987a088661a) (what is BoW approach in image?)
- [https://n1094.tistory.com/30](https://n1094.tistory.com/30) (spp layer performance in classificaton & detection)
- [https://blog.naver.com/laonple/220731472214](https://blog.naver.com/laonple/220731472214) (Laon people, 내용 생략 심함)
- [https://yeomko.tistory.com/14](https://yeomko.tistory.com/14) (SPPnet 전반적 흐름 & 설명)
- [https://www.youtube.com/watch?v=i0lkmULXwe0](https://www.youtube.com/watch?v=i0lkmULXwe0) (SPPnet 논문 강의 : 고려대학교 연구실)
- [https://89douner.tistory.com/89](https://89douner.tistory.com/89) (SPPnet 보충 설명 , 자세한)

> Fast R-CNN

- [https://arxiv.org/pdf/1504.08083.pdf](https://arxiv.org/pdf/1504.08083.pdf) (original fast r-cnn thesis)
- [https://fintecuriosity-11.tistory.com/73](https://fintecuriosity-11.tistory.com/73) (ablation study)
- [https://yeomko.tistory.com/15](https://yeomko.tistory.com/15) (how is end-to-end training possible?)
- [https://deepsense.ai/region-of-interest-pooling-explained/](https://deepsense.ai/region-of-interest-pooling-explained/) (spp vs roi pooling)

__`Next`__ : 2021.04.10 9:00 PM KST

- __Object Detection : Fast R-CNN details, ResNet fine-tuning practice (James , Jaden)__ 

> __Will Cover__ 
>
> - Fast R-CNN : 
>   - what's improved from SPP Net ? (idea, keywords)
>   - Fast R-CNN flow (rough) (compared with SPP Net)
>   - training Fast R-CNN (multi-task loss function, Hierarchical Sampling)
>   - test methods (truncated SVD)
>   - Fast R-CNN Limits
> - ResNet fine-tuning source code
>   - https://github.com/polospeter/TensorFlow-Advanced-Techniques-Specialization/blob/main/Course%203%20-%20Advanced%20computer%20vision%20with%20Tensorflow/Week%201/C3_W1_Lab_2_Transfer_Learning_CIFAR_10.ipynb

---

​	

### [2021.04.10]

__`Topic`__ : __Lecture 13.4: Object Detection : Fast R-CNN details, ResNet fine-tuning practice (James , Jaden)__ 

__`Notes`__ : 

- [https://drive.google.com/file/d/1ari0YxYTqaH9mky2pKkPOO9p15gX1EBS/view?usp=sharing](https://drive.google.com/file/d/1ari0YxYTqaH9mky2pKkPOO9p15gX1EBS/view?usp=sharing) [James]
- [https://drive.google.com/drive/folders/18WZeNJSrlOti07epXNy75Ws1s6U-Y-Q9?usp=sharing](https://drive.google.com/drive/folders/18WZeNJSrlOti07epXNy75Ws1s6U-Y-Q9?usp=sharing) [Jaden]

__`Links`__ : 

> Fast R-CNN

- [https://arxiv.org/pdf/1504.08083.pdf](https://arxiv.org/pdf/1504.08083.pdf) (original fast r-cnn thesis)
- [https://fintecuriosity-11.tistory.com/73](https://fintecuriosity-11.tistory.com/73) (ablation study)
- [https://yeomko.tistory.com/15](https://yeomko.tistory.com/15) (how is end-to-end training possible?)
- [https://deepsense.ai/region-of-interest-pooling-explained/](https://deepsense.ai/region-of-interest-pooling-explained/) (spp vs roi pooling)
- [https://ratsgo.github.io/deep%20learning/2017/04/05/CNNbackprop/](https://ratsgo.github.io/deep%20learning/2017/04/05/CNNbackprop/) (backprops in CNN layer)

> Res Net fine-tuning code

- [https://www.tensorflow.org/hub/tutorials/tf2_object_detection](https://www.tensorflow.org/hub/tutorials/tf2_object_detection) 
- [https://detectron2.readthedocs.io/en/latest/_modules/detectron2/modeling/roi_heads/fast_rcnn.html](https://detectron2.readthedocs.io/en/latest/_modules/detectron2/modeling/roi_heads/fast_rcnn.html) 
- [https://github.com/facebookresearch/detectron2/blob/master/detectron2/modeling/roi_heads/fast_rcnn.py](https://github.com/facebookresearch/detectron2/blob/master/detectron2/modeling/roi_heads/fast_rcnn.py) 
- [https://github.com/rbgirshick/py-faster-rcnn](https://github.com/rbgirshick/py-faster-rcnn) 

__`Next`__ : 2021.04.24 9:00 PM KST

- __DNN_practice & keras overview from Colab (James)__ 

> __Will Cover__ 
>
> - 자주 쓰게 될 서브 패키지 및 객체들
> - 3가지 모델 작성 법
> - 학습&테스트 과정 및 설정

---

​	

### [2021.04.24]

__`Topic`__ : __Special Course 1.DNN_practice & keras overview from Colab (James)__ 

__`Notes`__ : 

- [https://colab.research.google.com/drive/1hgquBEms7U-ZOff2x4OYy2Xzd8WZed5z?usp=sharing](https://colab.research.google.com/drive/1hgquBEms7U-ZOff2x4OYy2Xzd8WZed5z?usp=sharing) [James]

__`Links`__ : 

- [도큐먼트 짱](https://keras.io/api) 

- [https://wikidocs.net/106897](https://wikidocs.net/106897) (3-API) 

- [https://jjeongil.tistory.com/953](https://jjeongil.tistory.com/953) (evaluate) 

- [https://data-newbie.tistory.com/644](https://data-newbie.tistory.com/644) (performance visualization) 

__`Next`__ : 2021.05.01 9:00 PM KST

- __Inception module implementation from keras in Colab (Chloe)__ 

> - how to build Inception module with keras using Functional API method?

---

​	

### [2021.05.01]

__`Topic`__ : __Special Course 2. Keras overview & implementation of Inception block on Colab (James)__ 

__`Notes`__ : 

- [https://colab.research.google.com/drive/1hgquBEms7U-ZOff2x4OYy2Xzd8WZed5z?usp=sharing](https://colab.research.google.com/drive/1hgquBEms7U-ZOff2x4OYy2Xzd8WZed5z?usp=sharing) [James]

__`Links`__ : 

- [도큐먼트 짱](https://keras.io/api) 
- [https://wikidocs.net/106897](https://wikidocs.net/106897) (3-API) 
- [https://jjeongil.tistory.com/953](https://jjeongil.tistory.com/953) (evaluate) 
- [https://data-newbie.tistory.com/644](https://data-newbie.tistory.com/644) (performance visualization) 
- [https://nevfiasco.tistory.com/6](https://nevfiasco.tistory.com/6) (Inception block implementation)

__`Next`__ : 2021.05.08 9:00 PM KST

- __Object Detection: Faster R-CNN (Chloe, James)__ 

> 1. __What's improved? (or suggested?)__ 
>
> - 키워드별로 개념만, 뒤에 세부내용이 별도로 나옴
> - `RPN` , region proposal networks ( kind of FCN?)
> - Pyramids of images VS. Pyramids of filters VS. `Pyramids of Anchors` 
>
>
> 2. __Model architecture & Forward-pass (brief check)__ 
>
> - 마찬가지로 간단히
> - how a single image passs through model
>
> 3. __All about RPN__ 
>
> - 자세히
> - Inputs & Outputs
> - Anchor Box
>   - what is Anchor box & what does translation-invariant means
>   - how to refer anchor box to regression 
> - Loss
>   - what loss function is defined on  RPN?
> - Train
>   - how to train RPN?
>
> 4. __How RPN and Detector share feature maps?__ 
>
> - alternating training?
>
> 5. __Implementation details__ 
>
> - 가능한 정도만
> - used scales, anchor types

---

​	

### [2021.05.08]

__`Topic`__ : __Lecture 13.5: Object Detection Faster R-CNN part1 (Chloe, James)__ 

__`Notes`__ : 

- [https://drive.google.com/file/d/1--1Wj2JcrLcxMHPWoJNo24sPg2TAa-Go/view?usp=sharing](https://drive.google.com/file/d/1--1Wj2JcrLcxMHPWoJNo24sPg2TAa-Go/view?usp=sharing) [Chloe]
- [https://drive.google.com/file/d/16bjfABuBK1J-ejQRYNgOLjT2Z-iiqiu2/view?usp=sharing](https://drive.google.com/file/d/16bjfABuBK1J-ejQRYNgOLjT2Z-iiqiu2/view?usp=sharing) [James]

__`Links`__ : 

- [https://arxiv.org/pdf/1506.01497.pdf](https://arxiv.org/pdf/1506.01497.pdf) (Faster R-CNN original thesis) 
- [https://www.youtube.com/watch?v=46SjJbUcO-c&t=1451s](https://www.youtube.com/watch?v=46SjJbUcO-c&t=1451s) (기초개념 참고 유튜브 영상) 
- [https://deep-learning-study.tistory.com/464](https://deep-learning-study.tistory.com/464) (In/Out of RPN picture) 
- [https://herbwood.tistory.com/10](https://herbwood.tistory.com/10) (Training RPN details, KR) 
- [https://www.telesens.co/2018/03/11/object-detection-and-classification-using-r-cnns/](https://www.telesens.co/2018/03/11/object-detection-and-classification-using-r-cnns/) (Training RPN details, EN)
- [https://herbwood.tistory.com/11?category=867198](https://herbwood.tistory.com/11?category=867198) (코드로 이해하는 RPN)
- [https://medipixel.github.io/post/2019-06-14-anchor-target/#ref_7](https://medipixel.github.io/post/2019-06-14-anchor-target/#ref_7) (코드로 이해하는 RPN loss)
- [https://ganghee-lee.tistory.com/39](https://ganghee-lee.tistory.com/39) (FCN 참고자료 1)
- [https://medium.com/hyunjulie/1%ED%8E%B8-semantic-segmentation-%EC%B2%AB%EA%B1%B8%EC%9D%8C-4180367ec9cb](https://medium.com/hyunjulie/1%ED%8E%B8-semantic-segmentation-%EC%B2%AB%EA%B1%B8%EC%9D%8C-4180367ec9cb) (FCN 참고자료 2) 

__`Next`__ : 2021.05.15 9:00 PM KST

- __Object Detection: Faster R-CNN part2 (Hayden, James)__ 

> - __All about RPN__ 
>   - Train (how to train RPN?) 
> - __How RPN and Detector share feature maps?__ 
>   - 4-step alternating training
> - __Implementation details__ 
>   - 가능한 정도만
>   - used scales, anchor types
>
> \+ __multibox approach (pyramids of filters)__ 
>
> \+ __understanding regression loss of RPN__ 

---

__`스터디 RULE 수정`__ 

- 월/화 : 순서 변경이 필요한 팀원의 경우 화요일 저녁 전까지 다른 팀원에게 요청.
- 수: 해당 주 담당 팀원은 진행 정도 및 별도 준비가 필요한 부분을 James에게 전달.

---

​	

### [2021.05.15]

__`Topic`__ : __Lecture 13.5: Object Detection Faster R-CNN part2 (Hayden, James)__ 

__`Notes`__ : 

- [https://drive.google.com/file/d/1UdzLboCNc1Sda4ns83RVS-ar-JhcVCZl/view?usp=sharing](https://drive.google.com/file/d/1UdzLboCNc1Sda4ns83RVS-ar-JhcVCZl/view?usp=sharing) [Hayden]
- [https://drive.google.com/file/d/1OhM4QieuKMh_Nlv5WkWv0iZ4-MXBV_IK/view?usp=sharing](https://drive.google.com/file/d/1OhM4QieuKMh_Nlv5WkWv0iZ4-MXBV_IK/view?usp=sharing) [James]

__`Links`__ : 

- [https://herbwood.tistory.com/10](https://herbwood.tistory.com/10) (Training RPN details, KR) 
- [https://www.telesens.co/2018/03/11/object-detection-and-classification-using-r-cnns/](https://www.telesens.co/2018/03/11/object-detection-and-classification-using-r-cnns/) (Training RPN details, EN) 
- [https://nuggy875.tistory.com/33](https://nuggy875.tistory.com/33) (Lreg term of RPN loss) 
- [https://ganghee-lee.tistory.com/37](https://ganghee-lee.tistory.com/37) (4-step alternating trainging of Faster R-CNN) 
- [https://ratsgo.github.io/deep%20learning/2017/04/05/CNNbackprop/](https://ratsgo.github.io/deep%20learning/2017/04/05/CNNbackprop/) (remind of back-prop of maxpool layer)

__`Next`__ : 2021.05.22 9:00 PM KST

- __Object Detection: YOLO v1 (Chanju, James)__ 

> - 
>

---

​	

### [2021.05.23]

__`Topic`__ : __Programmers ML Dev-matching 참여 (전원)__ 

__`Notes`__ : 

- [https://programmers.co.kr/competitions/1109/2021-machinelearning](https://programmers.co.kr/competitions/1109/2021-machinelearning) [Programmers Link]

__`Links`__ : 

- `None` 

__`Next`__ : 2021.05.29 9:00 PM KST

- __Object Detection: YOLO v1 (Chloe, Chanju, James)__ 

> - __What's improved? (or suggested?)__ 
>   - object-detection as single-regression problem
>   - three benefits over traditional models
> - __Architecture & Computation flow__ 
>   - network design
>   - how raw image pass-through model (checking in/out of every layer)
> - __Train & Inference__ 
>   - understanding each term of sum-squared error
>   - using `λcoord` , `λnoobj` parameters
> - __Limits & Comparison to other previous models__ 
>   - limits : spatial constraint, small-object problem, coarse features, loss-balance
>   - comparison : `DPM` , `Deep MultiBox` , `OverFeat` , `MultiGrasp` 제외



---

​	

### [2021.05.29]

__`Topic`__ : __Object Detection: YOLO v1 (Chloe, Chanju, James)__ 

__`Notes`__ : 

- [https://drive.google.com/file/d/1WSqIcKwjyRALc4T3v0L3sBim5XuiSjkV/view?usp=sharing](https://drive.google.com/file/d/1WSqIcKwjyRALc4T3v0L3sBim5XuiSjkV/view?usp=sharing) [Chanju]
- [https://drive.google.com/file/d/18ITsaPJeyCBJVEUfjxaFFfgXxoiXjxk6/view?usp=sharing](https://drive.google.com/file/d/18ITsaPJeyCBJVEUfjxaFFfgXxoiXjxk6/view?usp=sharing) [James]
- [https://drive.google.com/file/d/1-61pnmfN_boV-Xgif2br8nUWN2hEh6Ge/view?usp=sharing](https://drive.google.com/file/d/1-61pnmfN_boV-Xgif2br8nUWN2hEh6Ge/view?usp=sharing) [Chloe]

__`Links`__ : 

- [https://arxiv.org/pdf/1506.02640.pdf ](https://arxiv.org/pdf/1506.02640.pdf) (원 논문)
- [https://jonathan-hui.medium.com/real-time-object-detection-with-yolo-yolov2-28b1b93e2088](https://jonathan-hui.medium.com/real-time-object-detection-with-yolo-yolov2-28b1b93e2088) (how output of final fc layer is tensor, not vector? => reshape, EN) 
- [https://curt-park.github.io/2017-03-26/yolo/](https://curt-park.github.io/2017-03-26/yolo/) (computation flow, KR)
- [https://kevin970401.github.io/cnn/2019/08/19/detection.html](https://kevin970401.github.io/cnn/2019/08/19/detection.html) (yolo limits, KR) 

__`Next`__ : 2021.06.05 9:00 PM KST

- __Recurrent Neural Network (Hayden, James)__ 

> - [https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/readings/L14%20Recurrent%20Neural%20Nets.pdf](https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/readings/L14%20Recurrent%20Neural%20Nets.pdf) 
>
> - __1.Introduction__ 
>   - Tasks predicting 'sequences'
>   - Neural Language Model to RNN
> - __2.Recurrent Neural Nets__ 
>   - unrolling network to understand like FFNN
>   - 3 examples of how parameter setting result in RNN
> - __3.Backprop Through Time__ 
>   - View as MLP backprop with unrolled computation-graph
>   - Comparing with MLP backprop
> - __4.Sequence Modeling (what tasks can RNN be applied)__ 
>   - Language Modeling
>   - Neural Machine Translation
>   - Learning to Execute Programs

​	

---

​	

### [2021.06.05]

__`Topic`__ : __Recurrent Neural Networks (Hayden, James)__ 

__`Notes`__ : 

- [https://drive.google.com/file/d/1qP1_SBwEeFE8CQ0T_Pd9veb2H6JEVRbP/view?usp=sharing](https://drive.google.com/file/d/1qP1_SBwEeFE8CQ0T_Pd9veb2H6JEVRbP/view?usp=sharing) [Hayden]
- [https://drive.google.com/file/d/1otSFBwYQcOD1dgZqup5ZhQkvX1HIalIW/view?usp=sharing](https://drive.google.com/file/d/1otSFBwYQcOD1dgZqup5ZhQkvX1HIalIW/view?usp=sharing) [James]

__`Links`__ : 

- [https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/readings/L14%20Recurrent%20Neural%20Nets.pdf](https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/readings/L14%20Recurrent%20Neural%20Nets.pdf) (CSC321, EN)
- [https://blog.naver.com/PostView.nhn?blogId=winddori2002&logNo=221974391796](https://blog.naver.com/PostView.nhn?blogId=winddori2002&logNo=221974391796) (RNN computation flow, KR) 
- [https://curt-park.github.io/2017-03-26/yolo/](https://curt-park.github.io/2017-03-26/yolo/) (computation flow, KR)
- [http://bigdata.dongguk.ac.kr/lectures/TextMining/_book/%EC%96%B8%EC%96%B4-%EB%AA%A8%EB%8D%B8language-model.html](http://bigdata.dongguk.ac.kr/lectures/TextMining/_book/%EC%96%B8%EC%96%B4-%EB%AA%A8%EB%8D%B8language-model.html) (Language Modeling, KR)
- [https://gruuuuu.github.io/machine-learning/lstm-doc/](https://gruuuuu.github.io/machine-learning/lstm-doc/) (why tanh is used, not sigmoid nor relu ?, KR) 

__`Next`__ : 2021.06.19 9:00 PM KST

- __Long Short Term Memory Networks (Jaden, James)__ 

> - [TBA](.)  

​	

---

​	

